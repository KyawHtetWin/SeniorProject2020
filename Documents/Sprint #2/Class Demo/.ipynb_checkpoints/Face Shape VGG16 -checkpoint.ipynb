{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights= 'imagenet',\n",
    "                 include_top= False,\n",
    "                 input_shape=(150,150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the architecture of VGG16 convolutional base\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Extracting features from the convolutional base '''\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "''' INSERT THE DIRECTORY WHERE YOU UNZIPPED THE DATA FILE '''\n",
    "base_dir = r''\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_sample_size = 400\n",
    "train_batch_size = 20\n",
    "\n",
    "valid_sample_size = 50\n",
    "valid_batch_size = 10\n",
    "\n",
    "test_sample_size = 50\n",
    "test_batch_size = 10\n",
    "\n",
    "datagen = ImageDataGenerator(rescale= 1./255)\n",
    "\n",
    "def extract_features(directory, sample_count, batch_size):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count, 5))\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "                        directory,\n",
    "                        target_size= (150, 150),\n",
    "                        batch_size= batch_size,\n",
    "                        class_mode= 'categorical')\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i*batch_size: (i+1)*batch_size] = features_batch\n",
    "        labels[i*batch_size: (i+1)*batch_size] = labels_batch\n",
    "        \n",
    "        i += 1\n",
    "        if i*batch_size >= sample_count:\n",
    "            break\n",
    "            \n",
    "    return features, labels\n",
    "\n",
    "# train_dir consists of 80 images per face shape class(5 face shape)\n",
    "train_features, train_labels = extract_features(train_dir, train_sample_size, train_batch_size)\n",
    "\n",
    "# validation_dir consists of 10 images per face shape class(5 face shape)\n",
    "validation_features, validation_labels = extract_features(validation_dir, valid_sample_size, valid_batch_size)\n",
    "\n",
    "# test_dir consists of 10 images per face shape class(5 face shape)\n",
    "test_features, test_labels = extract_features(test_dir, test_sample_size, test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reshape the extracted features of shape(samples, 4, 4, 512) into (samples,8192)\n",
    "before passing to the classifer\n",
    "'''\n",
    "train_features = np.reshape(train_features,(train_sample_size, 4*4*512))\n",
    "validation_features = np.reshape(validation_features,(valid_sample_size, 4*4*512))\n",
    "test_features = np.reshape(test_features, (test_sample_size, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation= 'relu', input_dim= 8192))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(5,activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_features, train_labels, epochs= 23,\n",
    "                    batch_size= 20, \n",
    "                    validation_data= (validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc'] \n",
    "val_acc = history.history['val_acc'] \n",
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc') \n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc') \n",
    "plt.title('Training and validation accuracy') \n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss') \n",
    "plt.title('Training and validation loss') \n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model \n",
    "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
    "print('Accuracy on test dataset: ', round(test_acc*100), '%' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
